{"version":3,"file":"async-batcher.cjs","sources":["../../src/async-batcher.ts"],"sourcesContent":["import { Store } from '@tanstack/store'\nimport { createKey, parseFunctionOrValue } from './utils'\nimport { emitChange, pacerEventClient } from './event-client'\nimport type { OptionalKeys } from './types'\n\nexport interface AsyncBatcherState<TValue> {\n  /**\n   * Number of batch executions that have resulted in errors\n   */\n  errorCount: number\n  /**\n   * Array of items that failed during batch processing\n   */\n  failedItems: Array<TValue>\n  /**\n   * Whether the batcher has no items to process (items array is empty)\n   */\n  isEmpty: boolean\n  /**\n   * Whether a batch is currently being processed asynchronously\n   */\n  isExecuting: boolean\n  /**\n   * Whether the batcher is waiting for the timeout to trigger batch processing\n   */\n  isPending: boolean\n  /**\n   * Array of items currently queued for batch processing\n   */\n  items: Array<TValue>\n  /**\n   * The result from the most recent batch execution\n   */\n  lastResult: any\n  /**\n   * Number of batch executions that have completed (either successfully or with errors)\n   */\n  settleCount: number\n  /**\n   * Number of items currently in the batch queue\n   */\n  size: number\n  /**\n   * Current processing status - 'idle' when not processing, 'pending' when waiting for timeout, 'executing' when processing, 'populated' when items are present, but no wait is configured\n   */\n  status: 'idle' | 'pending' | 'executing' | 'populated'\n  /**\n   * Number of batch executions that have completed successfully\n   */\n  successCount: number\n  /**\n   * Total number of items that have failed processing across all batches\n   */\n  totalItemsFailed: number\n  /**\n   * Total number of items that have been processed across all batches\n   */\n  totalItemsProcessed: number\n}\n\nfunction getDefaultAsyncBatcherState<TValue>(): AsyncBatcherState<TValue> {\n  return {\n    errorCount: 0,\n    failedItems: [],\n    isEmpty: true,\n    isExecuting: false,\n    isPending: false,\n    items: [],\n    lastResult: undefined,\n    settleCount: 0,\n    size: 0,\n    status: 'idle',\n    successCount: 0,\n    totalItemsProcessed: 0,\n    totalItemsFailed: 0,\n  }\n}\n\n/**\n * Options for configuring an AsyncBatcher instance\n */\nexport interface AsyncBatcherOptions<TValue> {\n  /**\n   * Custom function to determine if a batch should be processed\n   * Return true to process the batch immediately\n   */\n  getShouldExecute?: (\n    items: Array<TValue>,\n    batcher: AsyncBatcher<TValue>,\n  ) => boolean\n  /**\n   * Initial state for the async batcher\n   */\n  initialState?: Partial<AsyncBatcherState<TValue>>\n  /**\n   * Optional key to identify this async batcher instance.\n   * If provided, the async batcher will be identified by this key in the devtools and PacerProvider if applicable.\n   */\n  key?: string\n  /**\n   * Maximum number of items in a batch\n   * @default Infinity\n   */\n  maxSize?: number\n  /**\n   * Optional error handler for when the batch function throws.\n   * If provided, the handler will be called with the error, the batch of items that failed, and batcher instance.\n   * This can be used alongside throwOnError - the handler will be called before any error is thrown.\n   */\n  onError?: (\n    error: unknown,\n    batch: Array<TValue>,\n    batcher: AsyncBatcher<TValue>,\n  ) => void\n  /**\n   * Callback fired after items are added to the batcher\n   */\n  onItemsChange?: (batcher: AsyncBatcher<TValue>) => void\n  /**\n   * Optional callback to call when a batch is settled (completed or failed)\n   */\n  onSettled?: (batch: Array<TValue>, batcher: AsyncBatcher<TValue>) => void\n  /**\n   * Optional callback to call when a batch succeeds\n   */\n  onSuccess?: (\n    result: any,\n    batch: Array<TValue>,\n    batcher: AsyncBatcher<TValue>,\n  ) => void\n  /**\n   * Whether the batcher should start processing immediately\n   * @default true\n   */\n  started?: boolean\n  /**\n   * Whether to throw errors when they occur.\n   * Defaults to true if no onError handler is provided, false if an onError handler is provided.\n   * Can be explicitly set to override these defaults.\n   */\n  throwOnError?: boolean\n  /**\n   * Maximum time in milliseconds to wait before processing a batch.\n   * If the wait duration has elapsed, the batch will be processed.\n   * If not provided, the batch will not be triggered by a timeout.\n   * @default Infinity\n   */\n  wait?: number | ((asyncBatcher: AsyncBatcher<TValue>) => number)\n}\n\ntype AsyncBatcherOptionsWithOptionalCallbacks<TValue> = OptionalKeys<\n  Required<AsyncBatcherOptions<TValue>>,\n  | 'initialState'\n  | 'onError'\n  | 'onItemsChange'\n  | 'onSettled'\n  | 'onSuccess'\n  | 'key'\n>\n\nconst defaultOptions: AsyncBatcherOptionsWithOptionalCallbacks<any> = {\n  getShouldExecute: () => false,\n  maxSize: Infinity,\n  started: true,\n  throwOnError: true,\n  wait: Infinity,\n}\n\n/**\n * A class that collects items and processes them in batches asynchronously.\n *\n * This is the async version of the Batcher class. Unlike the sync version, this async batcher:\n * - Handles promises and returns results from batch executions\n * - Provides error handling with configurable error behavior\n * - Tracks success, error, and settle counts separately\n * - Has state tracking for when batches are executing\n * - Returns the result of the batch function execution\n *\n * Batching is a technique for grouping multiple operations together to be processed as a single unit.\n *\n * The AsyncBatcher provides a flexible way to implement async batching with configurable:\n * - Maximum batch size (number of items per batch)\n * - Time-based batching (process after X milliseconds)\n * - Custom batch processing logic via getShouldExecute\n * - Event callbacks for monitoring batch operations\n * - Error handling for failed batch operations\n *\n * Error Handling:\n * - If an `onError` handler is provided, it will be called with the error, the batch of items that failed, and batcher instance\n * - If `throwOnError` is true (default when no onError handler is provided), the error will be thrown\n * - If `throwOnError` is false (default when onError handler is provided), the error will be swallowed\n * - Both onError and throwOnError can be used together - the handler will be called before any error is thrown\n * - The error state can be checked using the AsyncBatcher instance\n *\n * State Management:\n * - Uses TanStack Store for reactive state management\n * - Use `initialState` to provide initial state values when creating the async batcher\n * - Use `onSuccess` callback to react to successful batch execution and implement custom logic\n * - Use `onError` callback to react to batch execution errors and implement custom error handling\n * - Use `onSettled` callback to react to batch execution completion (success or error) and implement custom logic\n * - Use `onExecute` callback to react to batch execution and implement custom logic\n * - Use `onItemsChange` callback to react to items being added or removed from the batcher\n * - The state includes total items processed, success/error counts, and execution status\n * - State can be accessed via `asyncBatcher.store.state` when using the class directly\n * - When using framework adapters (React/Solid), state is accessed from `asyncBatcher.state`\n *\n * @example\n * ```ts\n * const batcher = new AsyncBatcher<number>(\n *   async (items) => {\n *     const result = await processItems(items);\n *     console.log('Processing batch:', items);\n *     return result;\n *   },\n *   {\n *     maxSize: 5,\n *     wait: 2000,\n *     onSuccess: (result) => console.log('Batch succeeded:', result),\n *     onError: (error) => console.error('Batch failed:', error)\n *   }\n * );\n *\n * batcher.addItem(1);\n * batcher.addItem(2);\n * // After 2 seconds or when 5 items are added, whichever comes first,\n * // the batch will be processed and the result will be available\n * // batcher.execute() // manually trigger a batch\n * ```\n */\nexport class AsyncBatcher<TValue> {\n  readonly store: Store<Readonly<AsyncBatcherState<TValue>>> = new Store(\n    getDefaultAsyncBatcherState<TValue>(),\n  )\n  key: string\n  options: AsyncBatcherOptionsWithOptionalCallbacks<TValue>\n  #timeoutId: NodeJS.Timeout | null = null\n\n  constructor(\n    public fn: (items: Array<TValue>) => Promise<any>,\n    initialOptions: AsyncBatcherOptions<TValue>,\n  ) {\n    this.key = createKey(initialOptions.key)\n    this.options = {\n      ...defaultOptions,\n      ...initialOptions,\n      throwOnError: initialOptions.throwOnError ?? !initialOptions.onError,\n    }\n    this.#setState(this.options.initialState ?? {})\n\n    pacerEventClient.on('d-AsyncBatcher', (event) => {\n      if (event.payload.key !== this.key) return\n      this.#setState(event.payload.store.state)\n      this.setOptions(event.payload.options)\n    })\n  }\n\n  /**\n   * Updates the async batcher options\n   */\n  setOptions = (newOptions: Partial<AsyncBatcherOptions<TValue>>): void => {\n    this.options = { ...this.options, ...newOptions }\n  }\n\n  #setState = (newState: Partial<AsyncBatcherState<TValue>>): void => {\n    this.store.setState((state) => {\n      const combinedState = {\n        ...state,\n        ...newState,\n      }\n      const { isExecuting, isPending, items } = combinedState\n      const size = items.length\n      const isEmpty = size === 0\n      return {\n        ...combinedState,\n        isEmpty,\n        size,\n        status: isExecuting\n          ? 'executing'\n          : isPending\n            ? 'pending'\n            : isEmpty\n              ? 'idle'\n              : 'populated',\n      }\n    })\n    emitChange('AsyncBatcher', this)\n  }\n\n  #getWait = (): number => {\n    return parseFunctionOrValue(this.options.wait, this)\n  }\n\n  /**\n   * Adds an item to the async batcher\n   * If the batch size is reached, timeout occurs, or shouldProcess returns true, the batch will be processed\n   */\n  addItem = (item: TValue): void => {\n    this.#setState({\n      items: [...this.store.state.items, item],\n      isPending: this.options.wait !== Infinity,\n    })\n    this.options.onItemsChange?.(this)\n\n    const shouldProcess =\n      this.store.state.items.length >= this.options.maxSize ||\n      this.options.getShouldExecute(this.store.state.items, this)\n\n    if (shouldProcess) {\n      this.#execute()\n    } else if (this.options.wait !== Infinity) {\n      this.#clearTimeout() // clear any pending timeout to replace it with a new one\n      this.#timeoutId = setTimeout(() => this.#execute(), this.#getWait())\n    }\n  }\n\n  /**\n   * Processes the current batch of items asynchronously.\n   * This method will automatically be triggered if the batcher is running and any of these conditions are met:\n   * - The number of items reaches maxSize\n   * - The wait duration has elapsed\n   * - The getShouldExecute function returns true upon adding an item\n   *\n   * You can also call this method manually to process the current batch at any time.\n   *\n   * @returns A promise that resolves with the result of the batch function, or undefined if an error occurred and was handled by onError\n   * @throws The error from the batch function if no onError handler is configured or throwOnError is true\n   */\n  #execute = async (): Promise<any> => {\n    if (this.store.state.items.length === 0) {\n      return undefined\n    }\n\n    const batch = this.peekAllItems() // copy of the items to be processed (to prevent race conditions)\n    this.clear() // Clear items before processing to prevent race conditions\n    this.options.onItemsChange?.(this)\n\n    this.#setState({ isExecuting: true })\n\n    try {\n      const result = await this.fn(batch) // EXECUTE\n      this.#setState({\n        totalItemsProcessed:\n          this.store.state.totalItemsProcessed + batch.length,\n        lastResult: result,\n        successCount: this.store.state.successCount + 1,\n      })\n      this.options.onSuccess?.(result, batch, this)\n      return result\n    } catch (error) {\n      this.#setState({\n        errorCount: this.store.state.errorCount + 1,\n        failedItems: [...this.store.state.failedItems, ...batch],\n        totalItemsFailed: this.store.state.totalItemsFailed + batch.length,\n      })\n      this.options.onError?.(error, batch, this)\n      if (this.options.throwOnError) {\n        throw error\n      }\n      return undefined\n    } finally {\n      this.#setState({\n        isExecuting: false,\n        settleCount: this.store.state.settleCount + 1,\n      })\n      this.options.onSettled?.(batch, this)\n    }\n  }\n\n  /**\n   * Processes the current batch of items immediately\n   */\n  flush = async (): Promise<any> => {\n    this.#clearTimeout() // clear any pending timeout\n    return await this.#execute()\n  }\n\n  /**\n   * Returns a copy of all items in the async batcher\n   */\n  peekAllItems = (): Array<TValue> => {\n    return [...this.store.state.items]\n  }\n\n  peekFailedItems = (): Array<TValue> => {\n    return [...this.store.state.failedItems]\n  }\n\n  #clearTimeout = (): void => {\n    if (this.#timeoutId) {\n      clearTimeout(this.#timeoutId)\n      this.#timeoutId = null\n    }\n  }\n\n  /**\n   * Removes all items from the async batcher\n   */\n  clear = (): void => {\n    this.#setState({ items: [], failedItems: [], isPending: false })\n  }\n\n  /**\n   * Resets the async batcher state to its default values\n   */\n  reset = (): void => {\n    this.#setState(getDefaultAsyncBatcherState<TValue>())\n    this.options.onItemsChange?.(this)\n  }\n}\n\n/**\n * Creates an async batcher that processes items in batches\n *\n * Unlike the sync batcher, this async version:\n * - Handles promises and returns results from batch executions\n * - Provides error handling with configurable error behavior\n * - Tracks success, error, and settle counts separately\n * - Has state tracking for when batches are executing\n *\n * Error Handling:\n * - If an `onError` handler is provided, it will be called with the error, the batch of items that failed, and batcher instance\n * - If `throwOnError` is true (default when no onError handler is provided), the error will be thrown\n * - If `throwOnError` is false (default when onError handler is provided), the error will be swallowed\n * - Both onError and throwOnError can be used together - the handler will be called before any error is thrown\n * - The error state can be checked using the underlying AsyncBatcher instance\n *\n * State Management:\n * - Uses TanStack Store for reactive state management\n * - Use `initialState` to provide initial state values when creating the async batcher\n * - Use `onSuccess` callback to react to successful batch execution and implement custom logic\n * - Use `onError` callback to react to batch execution errors and implement custom error handling\n * - Use `onSettled` callback to react to batch execution completion (success or error) and implement custom logic\n * - Use `onExecute` callback to react to batch execution and implement custom logic\n * - Use `onItemsChange` callback to react to items being added or removed from the batcher\n * - The state includes total items processed, success/error counts, and execution status\n * - State can be accessed via the underlying AsyncBatcher instance's `store.state` property\n * - When using framework adapters (React/Solid), state is accessed from the hook's state property\n *\n * @example\n * ```ts\n * const batchItems = asyncBatch<number>(\n *   async (items) => {\n *     const result = await processApiCall(items);\n *     console.log('Processing:', items);\n *     return result;\n *   },\n *   {\n *     maxSize: 3,\n *     wait: 1000,\n *     onSuccess: (result) => console.log('Batch succeeded:', result),\n *     onError: (error) => console.error('Batch failed:', error)\n *   }\n * );\n *\n * batchItems(1);\n * batchItems(2);\n * batchItems(3); // Triggers batch processing\n * ```\n */\nexport function asyncBatch<TValue>(\n  fn: (items: Array<TValue>) => Promise<any>,\n  options: AsyncBatcherOptions<TValue>,\n) {\n  const batcher = new AsyncBatcher<TValue>(fn, options)\n  return batcher.addItem\n}\n"],"names":["Store","emitChange","parseFunctionOrValue","createKey","pacerEventClient"],"mappings":";;;;;AA4DA,SAAS,8BAAiE;AACxE,SAAO;AAAA,IACL,YAAY;AAAA,IACZ,aAAa,CAAA;AAAA,IACb,SAAS;AAAA,IACT,aAAa;AAAA,IACb,WAAW;AAAA,IACX,OAAO,CAAA;AAAA,IACP,YAAY;AAAA,IACZ,aAAa;AAAA,IACb,MAAM;AAAA,IACN,QAAQ;AAAA,IACR,cAAc;AAAA,IACd,qBAAqB;AAAA,IACrB,kBAAkB;AAAA,EAAA;AAEtB;AAoFA,MAAM,iBAAgE;AAAA,EACpE,kBAAkB,MAAM;AAAA,EACxB,SAAS;AAAA,EACT,SAAS;AAAA,EACT,cAAc;AAAA,EACd,MAAM;AACR;AA+DO,MAAM,aAAqB;AAAA,EAQhC,YACS,IACP,gBACA;AAFO,SAAA,KAAA;AART,SAAS,QAAoD,IAAIA,MAAAA;AAAAA,MAC/D,4BAAA;AAAA,IAAoC;AAItC,SAAA,aAAoC;AAwBpC,SAAA,aAAa,CAAC,eAA2D;AACvE,WAAK,UAAU,EAAE,GAAG,KAAK,SAAS,GAAG,WAAA;AAAA,IAAW;AAGlD,SAAA,YAAY,CAAC,aAAuD;AAClE,WAAK,MAAM,SAAS,CAAC,UAAU;AAC7B,cAAM,gBAAgB;AAAA,UACpB,GAAG;AAAA,UACH,GAAG;AAAA,QAAA;AAEL,cAAM,EAAE,aAAa,WAAW,MAAA,IAAU;AAC1C,cAAM,OAAO,MAAM;AACnB,cAAM,UAAU,SAAS;AACzB,eAAO;AAAA,UACL,GAAG;AAAA,UACH;AAAA,UACA;AAAA,UACA,QAAQ,cACJ,cACA,YACE,YACA,UACE,SACA;AAAA,QAAA;AAAA,MACV,CACD;AACDC,kBAAAA,WAAW,gBAAgB,IAAI;AAAA,IAAA;AAGjC,SAAA,WAAW,MAAc;AACvB,aAAOC,MAAAA,qBAAqB,KAAK,QAAQ,MAAM,IAAI;AAAA,IAAA;AAOrD,SAAA,UAAU,CAAC,SAAuB;AAChC,WAAK,UAAU;AAAA,QACb,OAAO,CAAC,GAAG,KAAK,MAAM,MAAM,OAAO,IAAI;AAAA,QACvC,WAAW,KAAK,QAAQ,SAAS;AAAA,MAAA,CAClC;AACD,WAAK,QAAQ,gBAAgB,IAAI;AAEjC,YAAM,gBACJ,KAAK,MAAM,MAAM,MAAM,UAAU,KAAK,QAAQ,WAC9C,KAAK,QAAQ,iBAAiB,KAAK,MAAM,MAAM,OAAO,IAAI;AAE5D,UAAI,eAAe;AACjB,aAAK,SAAA;AAAA,MAAS,WACL,KAAK,QAAQ,SAAS,UAAU;AACzC,aAAK,cAAA;AACL,aAAK,aAAa,WAAW,MAAM,KAAK,YAAY,KAAK,UAAU;AAAA,MAAA;AAAA,IACrE;AAeF,SAAA,WAAW,YAA0B;AACnC,UAAI,KAAK,MAAM,MAAM,MAAM,WAAW,GAAG;AACvC,eAAO;AAAA,MAAA;AAGT,YAAM,QAAQ,KAAK,aAAA;AACnB,WAAK,MAAA;AACL,WAAK,QAAQ,gBAAgB,IAAI;AAEjC,WAAK,UAAU,EAAE,aAAa,KAAA,CAAM;AAEpC,UAAI;AACF,cAAM,SAAS,MAAM,KAAK,GAAG,KAAK;AAClC,aAAK,UAAU;AAAA,UACb,qBACE,KAAK,MAAM,MAAM,sBAAsB,MAAM;AAAA,UAC/C,YAAY;AAAA,UACZ,cAAc,KAAK,MAAM,MAAM,eAAe;AAAA,QAAA,CAC/C;AACD,aAAK,QAAQ,YAAY,QAAQ,OAAO,IAAI;AAC5C,eAAO;AAAA,MAAA,SACA,OAAO;AACd,aAAK,UAAU;AAAA,UACb,YAAY,KAAK,MAAM,MAAM,aAAa;AAAA,UAC1C,aAAa,CAAC,GAAG,KAAK,MAAM,MAAM,aAAa,GAAG,KAAK;AAAA,UACvD,kBAAkB,KAAK,MAAM,MAAM,mBAAmB,MAAM;AAAA,QAAA,CAC7D;AACD,aAAK,QAAQ,UAAU,OAAO,OAAO,IAAI;AACzC,YAAI,KAAK,QAAQ,cAAc;AAC7B,gBAAM;AAAA,QAAA;AAER,eAAO;AAAA,MAAA,UACT;AACE,aAAK,UAAU;AAAA,UACb,aAAa;AAAA,UACb,aAAa,KAAK,MAAM,MAAM,cAAc;AAAA,QAAA,CAC7C;AACD,aAAK,QAAQ,YAAY,OAAO,IAAI;AAAA,MAAA;AAAA,IACtC;AAMF,SAAA,QAAQ,YAA0B;AAChC,WAAK,cAAA;AACL,aAAO,MAAM,KAAK,SAAA;AAAA,IAAS;AAM7B,SAAA,eAAe,MAAqB;AAClC,aAAO,CAAC,GAAG,KAAK,MAAM,MAAM,KAAK;AAAA,IAAA;AAGnC,SAAA,kBAAkB,MAAqB;AACrC,aAAO,CAAC,GAAG,KAAK,MAAM,MAAM,WAAW;AAAA,IAAA;AAGzC,SAAA,gBAAgB,MAAY;AAC1B,UAAI,KAAK,YAAY;AACnB,qBAAa,KAAK,UAAU;AAC5B,aAAK,aAAa;AAAA,MAAA;AAAA,IACpB;AAMF,SAAA,QAAQ,MAAY;AAClB,WAAK,UAAU,EAAE,OAAO,CAAA,GAAI,aAAa,CAAA,GAAI,WAAW,OAAO;AAAA,IAAA;AAMjE,SAAA,QAAQ,MAAY;AAClB,WAAK,UAAU,6BAAqC;AACpD,WAAK,QAAQ,gBAAgB,IAAI;AAAA,IAAA;AArKjC,SAAK,MAAMC,gBAAU,eAAe,GAAG;AACvC,SAAK,UAAU;AAAA,MACb,GAAG;AAAA,MACH,GAAG;AAAA,MACH,cAAc,eAAe,gBAAgB,CAAC,eAAe;AAAA,IAAA;AAE/D,SAAK,UAAU,KAAK,QAAQ,gBAAgB,CAAA,CAAE;AAE9CC,gBAAAA,iBAAiB,GAAG,kBAAkB,CAAC,UAAU;AAC/C,UAAI,MAAM,QAAQ,QAAQ,KAAK,IAAK;AACpC,WAAK,UAAU,MAAM,QAAQ,MAAM,KAAK;AACxC,WAAK,WAAW,MAAM,QAAQ,OAAO;AAAA,IAAA,CACtC;AAAA,EAAA;AAAA,EAlBH;AAAA,EA4BA;AAAA,EAyBA;AAAA,EAuCA;AAAA,EA4DA;AAqBF;AAmDO,SAAS,WACd,IACA,SACA;AACA,QAAM,UAAU,IAAI,aAAqB,IAAI,OAAO;AACpD,SAAO,QAAQ;AACjB;;;"}